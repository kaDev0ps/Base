# [Домашнее задание](https://github.com/a-prokopyev-resume/virt-homeworks/tree/virt-11/06-db-06-troobleshooting) к [занятию 6. «Troubleshooting»](https://netology.ru/profile/program/bd-dev-27/lessons/275716/lesson_items/1477627)## Задача 1Полезные материалы: * [Документация по администрированию MongoDB](https://docs.mongodb.com/manual/administration/) * [Запрос к perplexity.ai](https://www.perplexity.ai/search/27957b98-572e-4be5-820b-c65af49caa78) Поиск подвисшей CRUD операции в MongoDB:```db.currentOp({ "active" : true, "secs_running" : { "$gt" : 180 }})```Прерывание подвисшей операции:```db.killOp(op.opid)```Рекомендации по решению проблем с лагающими запросами в MongoDB:  * Можно добавить ограничение на длительность выполняемого запроса (maxTimeMS). * Мониторинг, чтобы понять, почему некоторые операции выполняются долго.   * Performance Advisor and Query Profiler (в MongoDB Atlas) для мониторинга медленных запросов.    * "Current Operations" в Studio 3T отображает запущенные операции, в т.ч. expiring.## Задача 2Полезные материалы: * [Документация по Redis latency troobleshooting](https://redis.io/topics/latency).Большое количество ключей, чьё время жизни истекает в одно время могут привести к тому, что Redis начинает блокировать записи.Redis может начать подвисать, если он обнаруживает более 25% ключей с истекшим TTL, потому что ему приходится очищать эти записи.Значение ACTIVE_EXPIRE_CYCLE_LOOKUPS_PER_LOOP указывает количество проверяемых на expiration ключей в каждом цикле (10 циклов в секунду).В новой версии Redis v6 используется более эффективный и точный способ поиска ключей с истекшим TTL за счёт сортировки Radix деревом вместо случайных рандомных samples. ## Задача 3Вы подняли базу данных MySQL для использования в гис-системе. При росте количества записей в таблицах базыпользователи начали жаловаться на ошибки вида:```pythonInterfaceError: (InterfaceError) 2013: Lost connection to MySQL server during query u'SELECT..... '```Как вы думаете, почему это начало происходить и как локализовать проблему?Какие пути решения этой проблемы вы можете предложить?Раз проблема возникла при росте объёма базы данных и в частности количества записей в таблицах, к которым осуществляются запросы, то скорее всего система не укладывается в старые временные промежутки для обеспечения того же самого функционала, т.е. проявляются проблемы с производительностью.Способы оптимизации:1) Проверить успевают ли передаваться данные с сервера на клиента за указанный timeout выполнения запроса. Проверить логи сообщений об ошибках.2) Проверить нагрузку на сервер СУБД (мониторинг сначала обычными системными и потом специальными утилитами) и попытаться его оптимизировать обычными методиками применимыми к любой современной промышленной СУБД уровня (IBM Db2, PostgreSQL, etc.), если нагрузка на сервер СУБД высокая:	1) Проверить эффективность работы встроенного оптимизатора запросов, % попадания в кэш, актуальность статистики, собранной для индексов.	2) Попытаться оптимизировать запрос вручную (возможно уменьшить возвращаемый по сети набор данных более узким условием WHERE), настроить индексы. Для этого нужно проверить планы выполнения запросов через оператор EXPLAIN.	3) Попытаться снизить объем запрашиваемых данных, 	4) Дисковый массив данных при большом проценте заполнения может начать лагать из-за фрагментации оставшегося свободного места. Померять актуыльные и максимальные показатели IOPs дисковой подсистемы.	5) Вертикальное масштабирование.	6) Партиционировать (и распределить по разным tablespaces на нескольких разных дисковых массивах) и/или шардировать таблицы по нескольким узлам кластера (горизонтальное масштабирование), readonly запросы можно распределить по readonly репликам primary сервера.	7) Проверить стабильность и скорость сетевого подключения при большой нагрузке на сеть.	8) Проверить нагрузку на клиента из-за увеличевшегося размера record sets, возвращаемых клиенту с сервера СУБД. Если клиент не справляется, нужно оптимизировать и его тоже.	9) Если устраивает длительная обработка запросов, то можно попробовать:*		Увеличить на сервере MySQL wait_timeout, max_allowed_packet, net_write_timeout и net_read_timeout*		Уменьшить pool_recycle, wait_timeout.## Задача 4Сообщение `postmaster invoked oom-killer` указывает на нехватку оперативной памяти для выполняемого процесса.1. Наростить объём RAM, убрать с сервера другие приложения.2. Произвести настройку параметров, затрагивающих память в Postgres: max_connections, shared_buffer, work_mem, effective_cache_size, maintenance_work_memБолее подробно о настройке памяти PostgreSQL можно прочитать по линку: https://www.enterprisedb.com/postgres-tutorials/how-tune-postgresql-memory3. Попытаться оптимизировать сервер СУБД по методике, описанной в задаче 2 для MySQL за исключением пункта 9.Если сервер будет быстрее обрабатывать запросы, то возможно, ему придётся хранить меньше данных в RAM в единицу времени, потому что упадёт количество одновременно обрабатываемых запросов (по сути одновременно запущенных процессов PostgreSQL, которые как раз и потребляют RAM).При этом TPS может наоборот вырасти.Вообще оптимизация сервера СУБД - это довольно комплексная задача, для решения которой нет короткого универсального рецепта, начинать надо с диагностики проблемы, и потом уже действовать по ситуации. Даже вертикальное масштабирование (RAM и количество процессорных ядер) сервера СУБД бывает абсолютно бесполезным при слабой дисковой подсистеме и недостаточно подходящей для тяжелых промышленных задач СУБД (например, Firebird v2), что можно было наблюдать на примере системы БПИ в ПФР.