
<!-- Мониторим:
Диск
Процессор
Оперативную память
Сетевая плата
Скорость записи диска -->

Когда тебя спросят на собеседовании, а что смотреть чтобы понять загружен ли сервер? То LA (load average) твой лучший помощник.

load average - среднее значение загрузки системы за некоторый период времени, как правило, отображается в виде трёх значений, которые представляют собой усредненные величины за последние 1, 5 и 15 минут, чем ниже, тем лучше.

"Нормальным" является значение, не превышающее кол-во ядер в системе. Грубо говоря если на машине стоит 4 ядерный процессов, то LA не должно быть выше 4.

# Мы поднимем с тобой тестовые Grafana, Prometheus, Node exporter

Давай для начала всё подготовим, а дальше я по шагам тебе уже всё объясню.

Мы сделаем тестовое окружение с помощью docker-compose, который поднимет нужные контейнеры.

Убедись, что у тебя на машине стоит docker, и docker-compose. В противном случае установи их.

https://docs.docker.com/compose/install/

https://docs.docker.com/get-docker/

Давай скачаем нужные файлы.

`curl -o docker-compose.yaml https://gist.githubusercontent.com/VegasCompany/712d65d41778e5a0a4350d94d02239dc/raw/ad1ccaaf45c22666e4a5c3d4af6c4403dde8e8d1/docker-compose.yaml`

Создай папку prometheus

`mkdir prometheus`

И ещё команда:

`curl -o "prometheus/prometheus.yml" https://gist.githubusercontent.com/VegasCompany/90e7419051a1418184579ec9a1ed4838/raw/fedbbd6d0684b51d8146019cb9f60a14e863427f/prometheus.yml`

Также папка с Grafana

`mkdir grafana`

`curl -o "grafana/datasource.yml" https://gist.githubusercontent.com/VegasCompany/60a4b1f0e476e403d0756c0ddcbb462d/raw/48f35a14223e4799a8b2ed190524d16a57983f40/datasource.yml`

Теперь введи:

`docker-compose up -d`

В этот момент docker compose всё поднимет согласно инструкциям, после выполнения проверь что всё три контейнера UP

# Отлично, теперь у нас есть тестовая среда. Давай теперь по порядку.

Начнём с того, что же всё-таки у нас используется. 
**Для отображения графиков изпользуется grafana, для хранения и управления метриками используется prometheus, а сами метрики на машине генерирует node_exporter.**

Все эти инструменты opensource, и являются самыми популярными под эти цели на момент написания статьи.

## Начнём с node_exporter.

Это обычная утилита, которая обращается к твоей системе, и генерирует метрики, которые понятны prometheus.

Отдаёт он их по /metrics.

Тоесть он собирает, например, сколько сейчас свободной памяти, записывает её под формат, который понимает prometheus, например:

node_pressure_memory_stalled_seconds_total 0

Попробуй запустить команду:

`curl localhost:9100/metrics`

Ты увидишь все метрики, которые сейчас отдаёт node_exporter на твоей системе.

Далее вступает в дело prometheus. Метрик много, также много и рабочих машин. Prometheus является централизованным хранилищем данных метрик. Он знает, что в момент X, метрика Y, была равна Z.

В начале идут довольно стандартные настройки, которые обычно не нужно менять, например частоту снятия метрик с хостов.

Prometheus умеет как сам ходить на нужный хост и забирать метрики, у, например, node_exporter. Это называется Pull модель. Так и exporter'ы умеют сами посылать метрики в prometheus. Это называется Push модель.

Кстати забыл сказать, exporter'ов существует очень много. Обычно это просто утилита, которая знает как обратиться к приложению, и посмотреть нужные данные.

Например наш node_exporter обращается к нашей системе и собирает нужные метрики.

#
Итак, давай обратно к конфигу.

В секции scrape_configs мы указываем с каких хостов забирать метрики. Там мы указываем job'ы. Это некое понятие prometheus. 

Грубо говоря, ты говоришь, слушай у тебя будет вот такой job:

- targets:

- localhost:9090

Иди в такой url, 

`metrics_path: /metrics`

По такому пути, и собирай метрики.

`scrape_interval: 15s`

Делай это раз в 15 секунд, чтобы не перегружать хост.

Давай-ка взглянем как выглядит наш prometheus. Смело переходи по:

http://localhost:9090

По ссылке ты попадёшь prometheus. Не бойся попереходить по вкладкам, ведь он тестовый.

В центре есть строка, где можно составить любой запрос, например такой:

`node_memory_MemFree_bytes`

Ты увидишь сколько свободной памяти в твоей системе в байтах.
#
Часто ставят exporter для базы данных, они уже есть готовые подо всё.

Exporter под mysql, psql.

Exporter для nginx, haproxy.

Под все популярные утилиты которыми мы пользуемся.

Это очень удобно, ведь тебе остаётся поднять exporter, и сказать prometheus ходить на него и собирать метрики.
#
Давай-ка попробуем визуализировать данные, в этом нам пригодится Grafana.

Смело открывай:

http://localhost:3000

Логин - admin

Пароль - grafana

Дашборд это сборник графиков, под разные метрики, например график потребления памяти. 

Чтобы не создавать его самому, давай импортируем готовый.

У grafana есть каталог дашбордов, вот тут - 

https://grafana.com/grafana/dashboards/

Давай я научу тебя устанавливать их

# Мы поставим dashboard для нашего node_exporter, чтобы посмотреть графики системы.

Ищи слева плюсик, и переходи в Import.

Там нужно ввести ID. 

Я уже нашёл dashboard

https://grafana.com/grafana/dashboards/1860

Справа есть поле с ID, введи его в своей grafana, нажми enter.

Она автоматически найдёт нужный dashboard, останется только в последнем поле выбрать DataSource

Это то место, откуда grafana будет брать данные для этого dashboard. В нашем случае это prometheus.

Перед тобой откроются графики, справа вверху выбери период в 15 минут. Я думаю понятно что это значит.

А теперь наслажайся картинкой, и посмотри все графики, это очень интересно. Я думаю нет смысла объяснять за каждый, предлагаю просто погуглить про те, которые ты не знаешь.

# Давай резюмируем:

Мы подняли docker контейнер с node_exporter, который собирает данные с твоей системы, и отображает их по /metrics.

Далее prometheus по Pull модели идёт, и собирает их, тк у него есть такая Job в конфиге.

Потом он их сохраняет.

После этого Grafana, в которую мы добавили нужный Dashboard с подходящими графиками, обращается к prometheus за данными, и рисует графики.

Мы рассмотрели с тобой основы самой популярной связки Prometheus + Grafana + Node_exporter. Впереди будет ещё много интересного, увидимся.