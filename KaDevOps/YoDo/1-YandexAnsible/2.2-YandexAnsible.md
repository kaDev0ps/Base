# В качестве Builder использовать виртуальную машину в облаках, а манипуляции на самой машине проводить с помощью ansible

Для начала надо поставить Packer и ansible, на сайте яндекса есть облачный репозиторий для установки Packer.

Документация Packer:

https://cloud.yandex.ru/docs/tutorials/infrastructure-management/packer-quickstart

На сайте Packer тоже есть пример для Yandex Cloud.

https://www.packer.io/plugins/builders/yandex

Документация Ansible:

https://docs.ansible.com/ansible/latest/installation_guide/intro_installation.html

https://www.digitalocean.com/community/tutorials/how-to-install-and-configure-ansible-on-ubuntu-22-04

Далее установим Интерфейс командной строки Yandex Cloud (CLI) — скачиваемое программное обеспечение для управления вашими облачными ресурсами через командную строку.

Документация:

https://cloud.yandex.ru/docs/cli/quickstart#install

Потом создадим сервисный аккаунт

https://cloud.yandex.ru/docs/tutorials/infrastructure-management/jenkins

Создать сервисный аккаунт

https://cloud.yandex.ru/docs/iam/quickstart-sa

Также надо будет получить IAM токен для сервисного аккаунта. Это ssh ключ  RSA_2048 по которому мы будем подключаться.

https://cloud.yandex.ru/docs/iam/operations/iam-token/create-for-sa

Во время все этого ты будешь получать некие ID, их и нужно заводить в конфиги в файле vars.json и template.json

Потом через Packer собираешь образ как в уроке
# Теперь надо создать платежный аккаунт.

https://cloud.yandex.ru/docs/getting-started/quickstart-individuals

Замечательно, давай приступим к созданию нашего образа, для этого сначала установим локально Packer.
Переходи по ссылке, и выбирай нужный установщик под свой дистрибутив.

https://packer.io/downloads.html

Обычно, если написать название инструмента, а потом help, или --help, или -h (сокращенно help), то она подскажет, какие команды и ключи она поддерживает.

Например:

`packer --help`

Packer оперирует шаблонами, и переменными для них.  Начнем с создания папки под проект и подготовке необходимых файлов. О них я буду рассказывать далее, не переживай. Создай любую папку, и перейди в нее.

# Документация работы с Packer

https://cloud.yandex.ru/docs/tutorials/infrastructure-management/packer-quickstart

Дальше создай файл с именем

template.json

И скопируй в него следующий код по ссылке:

template.json
Рядом создай файл vars.json, и положи в него содержимое по ссылке:

vars.json

Ansible очень удобный инструмент, который каждый день помогает системному администратору сэкономить большое количество времени, но о нем будет в другом месте, пока переходи по ссылке, и выбирай подходящий способ установки:

https://docs.ansible.com/ansible/latest/installation_guide/intro_installation.html

Довольно просто проверить все ли ок, введи в командной строке:

`ansible -h`

Если тебе выдалась справка, то все ок, продолжаем.

Тогда создай третий файл, назови его main.yml, и положи в него следующее содержимое по ссылке:

https://gist.github.com/VegasCompany/18f001ccecc977041603aec08a0fb882/raw/b018c0c65ba5df9e18bce1b134fc5ddd49aab662/main.yml

# Начнем с файла tempate.json

Открой его в любом редакторе, посмотрим что там понаписано.

Начнем сначала, template (шаблон, сценарий) для packer пишется на json языке.

Там есть две основных для нас секции:

- builders

- provisioners

Начнем с builders.

В этом блоке, мы объясняем packer'у, с помощью каких ресурсов мы будем собирать образ. Ведь для создания образа, ему нужно где-то запустить исходный, потом с ним что-то сделать, а потом запаковать обратно в образ версия 2, например.

В нашем примере, мы используем мощности Yandex Cloud для этого. Packer создаст виртуальную машину (instance) и запустит ее из образа debian11.

Билдеров есть много, их все можно посмотреть в документации: https://www.packer.io/docs/builders

Также есть provisioners.

Они нужны для того, чтобы сделать изменения на ИСХОДНОМ образе. И в итоге получить КОНЕЧНЫЙ образ (image).

Их тоже довольно много, мы будем использовать ansible. В него я погружаться не буду, об этом в другом задании.

Список доступных provisioners можно подсмотреть тут:

https://packer.io/docs/provisioners/index.html

У тебя в папке, есть файл vars.json

В нем хранятся переменные, для твоего шаблона (template.json).

Это правило хорошего тона, написать один раз template (шаблон), а далее подставлять в него значения из переменных (vars.json)

Заскриню, слева будет template.json, а справа в редакторе будет vars.json. Переменные справа будут подставляться в шаблон слева.

Напомню, что image - это образ виртуальной машины, из которой можно будет его создать.

Тебе нужно будет изменить несколько значений, а также **создать сервисный аккаунт для Packer.** 

Обязательные значения, которые нужно поменять product_images_project_id и cloud_subnet_id

Итак, открой файл vars.json в любом редакторе, там есть строка:

`"product_images_project_id": "b1g48sh8h3l4f9cur6k2"`

В Yandex Cloud, грубо говоря, все разделено по иерархии на проекты. Тебе нужно указать свой, для этого вернись к консоли и вставь значение из примера на скрине.

# Также там есть интересные переменные:

Zone можно взять любую, весь список здесь -

https://cloud.yandex.ru/docs/overview/concepts/geo-scope

`"zone": "ru-central1-a",`

Product_name - Это то, как будет называться твой образ, можешь заменить на что-то свое, но пока не рекомендую :)

`"product_name": "debian11-withnginx-user1-v1",`

Yandex Cloud при запуске виртуальной машины (instance) предлагает уже свои заготовленные images

`"source_image_family": "debian-11",`

Ну а это просто описание :)

`"image_description": "My image for user1, with nginx on board."`
В файле template.json, мы прописали использовать для подключения данные из аккаунта account.json

За это отвечает эта строка:

`"service_account_key_file: "/путь до файла/key.json"`

# Давай же этот файл создадим, переходим обратно в Yandex Cloud

Инструкция создание каталога

https://cloud.yandex.ru/docs/resource-manager/operations/folder/create



Инструкция по мозданию сервисного аккаунта.

https://cloud.yandex.ru/docs/iam/quickstart-sa



Инструкция создать сервисный аккаунт в терминале.

https://cloud.yandex.ru/docs/cli/quickstart

# Назовем его debian-11

https://console.cloud.yandex.ru/cloud

Переходим по ссылке и в верхнем правом углу жмем создать каталог.

Теперь тебе надо прописать id каталога в product_images_project_id

Далее  Сервисные аккаунты и жмем кнопку Создать сервисный аккаунт, чтобы создать его.

Но не спешите создавать его.

Создадим его через терминал.

Заполняем имя и жмем Create.

# Также можно создать сервисный аккаунт в терминале

https://cloud.yandex.ru/docs/tutorials/infrastructure-management/jenkins#configure-jenkins

Назову его account-for-packer

Но сначала получим OAuth токен, чтоб можно было работать в терминале

https://cloud.yandex.ru/docs/cli/quickstart

Вводим 

`yc init`

вводим токен и выбираем нужные варианты из предложенных.

Создайте сервисный аккаунт и передайте его идентификатор в переменную окружения, выполнив команды:

`yc iam service-account create --name account-for-packer`

`yc iam key create --service-account-name account-for-packer -o account.json`

`SERVICE_ACCOUNT_ID=$(yc iam service-account get --name account-for-packer --format json | jq -r .id)`

В текущем каталоге будет создан JSON-файл, содержащий авторизационные данные.

Далее нам предлагают навесить роли на наш новосозданный аккаунт. Роли нужны, чтобы разрешить аккаунту делать что-то определенное, например только запускать виртуальные машины.

Вот здесь я подсмотрел какие роли нужны -

https://cloud.yandex.ru/docs/iam/operations/sa/assign-role-for-sa

# Назначьте сервисному аккаунту роль admin на каталог, где будут выполняться операции:

`yc resource-manager folder add-access-binding debian-11 --role admin --subject serviceAccount:$SERVICE_ACCOUNT_ID`

Далее нам предлагают навесить роли на наш новосозданный аккаунт. Роли нужны, чтобы разрешить аккаунту делать что-то определенное, например только запускать виртуальные машины.

Вот здесь я подсмотрел какие роли нужны -

https://cloud.yandex.ru/docs/iam/operations/sa/assign-role-for-sa

Назначьте сервисному аккаунту роль admin на каталог, где будут выполняться операции:

`yc resource-manager folder add-access-binding debian-11 --role admin --subject serviceAccount:$SERVICE_ACCOUNT_ID`

У тебя скачается ключ,

key.json

 в папку, где сейчас лежат три файла для Packer.

Продолжай только после того, как в папке будет 4 файла:

- template.json (сам сценарий)

- vars.json (переменные для него)

- key.json (файл, который ты сейчас скачал)

- main.yml (ansible задание для установки nginx, docker)

# Настал час X. Мы можем сначала проверить все ли окей, а потом и собрать наконец-то наш образ.

Ты сейчас находишься в папке с файлами, введи команду:

`packer validate -var-file=vars.json template.json`


Она подскажет, нигде ли ты случайно не стер запятую, или не пропустил кавычку.

Она должна вывести на экран что-то наподобие:

Template validated successfully.

Тогда вводи:

`packer build -var-file=vars.json template.json`

Эта команда запустит сборку твоего образа. Тебе лишь остается сидеть и наблюдать

В конце ты увидишь сообщение:

==> Builds finished. The artifacts of successful builds are:
--> yandex: A disk image was created: debian11-withnginx-user1-v1-builder (id: fd8h51b28hpijjbnbrtc) with family name 

Оно говорит о том, что твой образ (image) создан, и его название - debian11-withnginx-user1-v1

Запомни его. Дальше мы будем делать машину из этого образа с помощью Terraform!
# Кстати свой образ всегда можно найти по ссылке:

https://cloud.yandex.ru/docs/compute/operations/images-with-pre-installed-software/get-list

****************************
********* TERRAFORM ********
****************************

Terraform это тоже продукт от компании Hashicorp. Он нужен для того, чтобы описать твою инфраструктуру кодом. Тоесть ты не пошел и натыкал что-то в yc, а у тебя есть код, который говорит, сделай эту машину, с таким адресом.

Terraform является клиентом и необходимо выполнить установку на компьютер, с которого планируется управление инфраструктурой. Актуальная инструкция по развертыванию представлена на официальном сайте. На текущий момент клиент может быть установлен из репозитория, с использованием бинарника, собран из исходников.

Скачиваем бинарник

Посмотреть ссылку на него можно на странице официального сайта:

`wget https://releases.hashicorp.com/terraform/1.2.8/terraform_1.2.8_linux_amd64.zip`

Распаковываем

`unzip terraform_*_linux_amd64.zip`

Перенесем распакованный бинарник в каталог:

`mv terraform /usr/local/bin/`

Убедимся, что terraform работает. Для этого вводим команду:

`terraform -version`

Мы должны получить что-то наподобие: В моем случае

Terraform v1.2.8
on linux_amd64

Теперь создадим каталог, в котором будем работать со сценариями для terraform:

Создайте каталог на компьютере, там где вам удобно.

# Перейдем в созданный каталог

Чтобы terraform мог корректно взаимодействовать с инфраструктурой провайдера, необходимо использовать набор инструкций, которые будет использовать наша утилита. В терминологии terraform это называется провайдер.

На сайте Hashicorp можно найти все поддерживаемые провайдеры. У нас Yandex.Cloud. 

В нашем рабочем каталоге создаем первый файл:

Инструкция здесь

`nano main.tf`

<!-- 
terraform {

  required_version = "= 1.2.8"



  required_providers {

    yandex = {

      source  = "yandex-cloud/yandex"

      version = "= 0.73"

    }

  }

}



provider "yandex" {

token  = ""

cloud_id = "

folder_id = "

zone = "

} 
-->

source — глобальный адрес источника провайдера.

terraform required_version — версия клиента terraform, для которого должен запускаться сценарий. Параметр не обязательный, но является правилом хорошего тона и может помочь избежать некоторых ошибок, которые возникнут из-за несовместимости при работе в команде.

required_providers version — версия провайдера. Мы можем указать, как в данном примере, необходимость использовать конкретную версию, а можно с помощью знака >= или 

token  — OAuth-токен для доступа к Yandex Cloud.

cloud_id — идентификатор облака, в котором Terraform создаст ресурсы.

folder_id — идентификатор каталога, в котором по умолчанию будут создаваться ресурсы.

zone — зона доступности, в которой по умолчанию будут создаваться все облачные ресурсы.

Если вдруг забыли команду, чтоб выдала вам OAuth-token и id_folder вводим в консоли

yc config list

 и заполняем файл main.tf

 выполняем команду:

`terraform init`

Система загрузит нужные файлы и установит провайдер
Если все хорошо, то двигаемся дальше.

Мы рассмотрим небольшие примеры по созданию, редактированию и удалению ресурсов. В большей степени мы будем работать с виртуальными машинами. Большую часть информации по написанию сценариев можно найти на официальном сайте хостинга или самого terraform.

# Создадим ресурс

В каталоге создадим файл infrastructure.tf

`nano infrastructure.tf`

<!-- data "yandex_compute_image" "debian_image" {

family = "debian-11"

}

resource "yandex_compute_instance" "vm-debian" {

name = "debian"

resources {

cores = 2

memory = 2

}

boot_disk {

initialize_params {

image_id = 

}

}

network_interface {

subnet_id = yandex_vpc_subnet.subnet_terraform.id

nat  = true

}

metadata = {

user-data = "${file("./meta.yml")}"

}

}

resource "yandex_vpc_network" "network_terraform" {

name = "net_terraform"

}

resource "yandex_vpc_subnet" "subnet_terraform" {

name  = "sub_terraform"

zone  = "ru-central1-a"

network_id  = yandex_vpc_network.network_terraform.id

v4_cidr_blocks = ["192.168.15.0/24"]

} -->

data — позволяет запрашивать данные. В данном примере мы обращаемся к ресурсу yandex_compute_image с целью поиска идентификатора образа, с которого должна загрузиться наша машина.yandex_compute_image — ресурс образа. Его название определено провайдером.
debian_image — произвольное название ресурса. Его мы определили сами и будем использовать в нашем сценарии.
debian-11 — в нашем примере мы запрашиваем данные ресурса, который ищем по family с названием debian-11. Данное название можно посмотреть в контроль панели хостинга — нужно выбрать образ и кликнуть по нему. Откроется страница с дополнительной информацией. В данном случае debian-11 соответствуем debian-11.

Все образы можно посмотреть командой

`yc compute image list --folder-id standard-images`

resource — позволяет создавать различные ресурсы.yandex_compute_instance — ресурс виртуальной машины. Его название определено провайдером.
vm-debian — наше название ресурса для виртуальной машины.

image_id - Идентификатор существующего образа для использования в качестве источника образа. Изменение этого идентификатора приводит к созданию нового ресурса. Здесь указываем id нашего образа, который мы создавали с помощью Packer.

По умолчанию, если нет образов вписываем:

`data.yandex_compute_image.ubuntu_image.id`


yandex_vpc_network — ресурс сети, определенный провайдером.
network_terraform — наше название для ресурса сети.
yandex_vpc_subnet — ресурс подсети, определенный провайдером.
subnet_terraform — наше название для ресурса подсети.
metadata — обратите особое внимание на передачу метеданных. В данном примере мы передаем содержимое файла, а сам файл рассмотрим дальше.

Будет создана ВМ названием debian, 2 CPU, 2 Gb RAM в сети 192.168.15.0/24 на базе Debian-11.

Создаем файл с метаданными meta.yml

`nano meta.yml`

<!-- #cloud-config

users:

- name: test

groups: sudo

shell: /bin/bash

sudo: ['ALL=(ALL) NOPASSWD:ALL']

ssh-authorized-keys:

- ssh-rsa AAAAB7dd6r..................R4tgDDDf5r/hRR4dd= -->

#cloud-config — как выяснилось, этот комментарий обязательный.

name — имя пользователя, который будет создан на виртуальной машине.

groups — в какую группу добавить пользователя.

shell — оболочка shell по умолчанию.

sudo — правило повышения привилегий.

ssh-authorized-keys — список ключей, которые будут добавлены в authorized_keys.

Создать ключи командой:

Создание пары ключей SSH

`ssh-keygen -t rsa -b 2048`

После прописываем публичный ключ

Далее
Проверьте конфигурацию командой:

`terraform validate`

Если конфигурация является допустимой, появится сообщение:

Success! The configuration is valid.

Отформатируйте файлы конфигураций в текущем каталоге и подкаталогах:

`terraform fmt`

вывод будет каким:

<!-- infrastructure.tf

main.tf -->

После проверки конфигурации выполните команду:

`terraform plan`

В терминале будет выведен список ресурсов с параметрами. Это проверочный этап: ресурсы не будут созданы. Если в конфигурации есть ошибки, Terraform на них укажет.

После того, как мы убедимся в корректности действий, применяем настройку:

`terraform apply`

Мы еще раз увидим, что будет выполнено, а также получим запрос на подтверждение действий — вводим yes:


Terraform выполнит необходимые действия. Мы можем перейти в контроль-панель хостинга и убедиться, что наша виртуальная машина создалась.


Чтобы удалить ресурсы, созданные с помощью Terraform: Выполните команду:

`terraform destroy`



Теперь, что если нам необходимо внести изменения в нашу инфраструктуру, то достаточно просто открыть наш файл со сценарием: infrastructure.tf



Вводим нужные изменения, например:

<!-- resources {

cores = 4

memory = 4

} -->

Тут мы просто увеличили количество процессоров и объем памяти для созданной виртуальной машины

Важно знать, что некоторые изменения требуют остановки виртуальной машины. При попытке применить новые настройки  мы получим ошибку с текстом:

Error: Changing the `secondary_disk`, `resources`, `platform_id`, `network_acceleration_type` or `network_interfaces` on an instance requires stopping it. To acknowledge this action, please set allow_stopping_for_update = true in your config file.

Ясно
Мы должны явно разрешить для конкретных ресурсов выполнение остановки их работы для внесения изменений. В нашем файле для конкретного ресурса добавим:

<!-- resource "yandex_compute_instance" "vm-debian" {

name = "debian"

allow_stopping_for_update = true -->

для нашей машины debian мы указали опцию allow_stopping_for_update, которая говорит о том, что работу ресурса можно останавливать для внесения изменений.

Запускаем

`terraform plan`

Мы должны увидеть, что будет изменено в нашей инфраструктуре. В моем случае:

~ resources {

~ cores  = 2 -> 4

~ memory = 2 -> 4

# (2 unchanged attributes hidden)

}

Применяем:

`terraform apply`

Для удаления ресурса можно использовать разные приемы.

Например, можно указать count = 0:

resource "yandex_compute_instance" "vm-debian" {

count = 0

Можно закомментировать или удалить строки ресурса из файла tf.

Если мы хотим оставить содержимое файлов нетронутым, но при этом удалить все ресурсы, вводим:

`terraform destroy`

Утилита пройдет по всем файлам tf в директории, найдет ресурсы и выполнит их удаление.

# Теперь рассмотрим как всем этим работать.

## Файл tfstate

В нем содержатся все изменения, которые происходили с применением terraform. Без него последний не будет знать, что уже было сделано — на практике это приведет к дублированию инфраструктуры, то есть, если мы создали сервер, потеряли файл состояния и снова запустили terraform, он создаст еще один сервер. Для больших инфраструктур с большой историей все намного критичнее.

И так, файл состояния важен с точки зрения понимания инфраструктуры самим terraform. Также у него есть еще одна функция — блокировка параллельных выполнений. Это важно для работы в командах, где одновременные действия могут привести к неожиданным последствиям. Чтобы этого не произошло, terraform создает блокировку, которая запрещает выполнения, если уже идет процесс применения плана.

Из вышесказанного делаем выводы:

Файлы состояния нужно бэкапить.
Они должны находиться в надежном месте.
У всех инженеров, которые работают с инфраструктурой должен быть доступ к файлу состояния. Они не должны его копировать на свои компьютеры и использовать индивидуально.
Рассмотрим возможность хранения данного файла состояния на облачном хранилище Яндекс.

# Сначала мы должны создать хранилище. Это можно сделать через веб-интерфейс, но мы это сделаем в terraform.

Но сначала мы создадим файл:

<!-- 
nano variables.tf

variable "yandex_folder_id" {

type = string

default  = "

} 
-->

где yandex_folder_id — название для нашей переменной;  тот идентификатор, который мы указали в файле main под аргументом folder_id.

# Теперь откроем файл main:

`nano main.tf`

И отредактируем значение folder_id на:

`folder_id = var.yandex_folder_id`

в данном примере мы теперь задаем folder_id не явно, а через созданную переменную


# Теперь создадим файл:

`nano yandex_storage_bucket.tf`

<!-- resource "yandex_iam_service_account" "sa" {

folder_id = var.yandex_folder_id

name = "sa-debian"

}

resource "yandex_resourcemanager_folder_iam_member" "sa-editor" {

folder_id = var.yandex_folder_id

role = "storage.editor"

member = "serviceAccount:${yandex_iam_service_account.sa.id}"

}

resource "yandex_iam_service_account_static_access_key" "sa-static-key" {

service_account_id = yandex_iam_service_account.sa.id

description = "Static access key for object storage"

}

resource "yandex_storage_bucket" "state" {

bucket  = "tf-state-bucket-debian"

access_key = yandex_iam_service_account_static_access_key.sa-static-key.access_key

secret_key = yandex_iam_service_account_static_access_key.sa-static-key.secret_key

} -->

yandex_iam_service_account — создание ресурса для учетной записи. В нашем примере она будет иметь название sa-debian и входить в системный каталог yandex_folder_id (переменная, которую мы создали ранее).
yandex_resourcemanager_folder_iam_member — создание роли. Она будет иметь доступ для редактирования хранилищ. В состав роли войдет созданная запись sa (с именем sa-debian).
yandex_iam_service_account_static_access_key — создаем ключ доступа для нашей сервисной учетной записи.
yandex_storage_bucket — создаем хранилище с названием tf-state-bucket-debian.

# Создадим еще один файл:

`nano outputs.tf`

<!-- output "access_key" {

value = yandex_iam_service_account_static_access_key.sa-static-key.access_key

sensitive = true

}

output "secret_key" {

value = yandex_iam_service_account_static_access_key.sa-static-key.secret_key

sensitive = true

} -->

это делается для получения значений аргументов access_key и secret_key и сохранения данных значений в файле состояния. Если access_key можно посмотреть в панели Яндекса, то secret_key мы увидеть не можем.

Строим план и применяем настройки:

`terraform plan`

`terraform apply`

Заходим в контроль панель Яндекса и видим, что у нас создалось хранилище. Его мы будем использовать для хранения файлов состояний terraform.

# Открываем наш файл main:

`nano main.tf`

Добавляем:

<!-- 
backend "s3" {

  endpoint   = "storage.yandexcloud.net"

  bucket     = "tf-state-bucket-debian-ka"

  region     = "ru-central1-a"

  key        = "terraform/infrastructure/terraform.tfstate"

  access_key = ""

  secret_key = ""

 

  skip_region_validation      = true

  skip_credentials_validation = true

  }

} 
-->

Если будет ругаться, то добавьте этот код в блок terraform


* в раздел terraform мы добавили инструкцию для хранения файла state. В нашем примере он будет размещен на бакете tf-state-bucket-debian-ka по пути terraform/infrastructure/terraform.tfstate.
** особое внимание обратите на access_key и secret_key. В разделе terraform мы не можем указать переменные, как это делали при создании хранилища. Сами значения можно найти в нашем локальном файле terraform.tfstate.

"secret_key": "YCNilkrAqw31T5ovWcSRLeo9JKXakY2pkF-L2AlK",
"access_key": "YCAJEUvzAAZNvDWwyseC5r6Du",

В итоге получим main.tf вида
<!-- 
terraform {

  required_version = "= 1.2.8"



  required_providers {

    yandex = {

      source = "yandex-cloud/yandex"

      version = "= 0.73"

    }

  }

backend "s3" {

  endpoint   = "storage.yandexcloud.net"

  bucket     = "tf-state-bucket-debian-ka"

  region     = "ru-central1-a"

  key        = "terraform/infrastructure/terraform.tfstate"

  access_key = "YCAJEUvzAAZNvDWwyseC5r6Du"

  secret_key = "YCNilkrAqw31T5ovWcSRLeo9JKXakY2pkF-L2AlK"



  skip_region_validation      = true

  skip_credentials_validation = true

  }

}

provider "yandex" {

  token = "y0_AgAAAAARB_HiAATuwQAAAAD47wPMS5I3f66RT6OSHewKkbrhw_EohHk"

  cloud_id = "b1g3cd8s33rf8m9v2ivn"

  folder_id = var.yandex_folder_id

  zone = "ru-central1-a"
} -->

# Используем команду:,

`terraform init`

Система снова инициализирует состояние текущего каталога и создаст файл state на удаленном хранилище. Чтобы убедиться, можно зайти в контроль панель, найти наше хранилище, а в нем — файл terraform/infrastructure/terraform.tfstate.

Не забудьте удалить все что создали, если не используете. 

Фух, кажется можно отдавать заказчику, давай проговорим все, что мы сделали:
Взяли образ debian 11, с помощью ansible установили в него nginx, docker, положили это все к нам в проект yc
Дальше ты немного больше разобрался, зачем же нужно описывать инфраструктуру именно как код. Ты описал один раз, а дальше сколько угодно раз просто повторяешь. Не нужно каждый раз делать руками.

Ты разобрался с terraform, научился хранить его state в удаленном хранилище (bucket), о котором не нужно беспокоиться, а не сломается ли в нем диск.

После этого ты описал виртуальную машину, сделал plan изменений, и применил их.