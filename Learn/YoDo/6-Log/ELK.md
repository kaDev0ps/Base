Elastic Stack — ранее известный как стек (ELK расшифровывается как ElasticSearch + LogStash + Kibana.)— представляет собой набор программного обеспечения с открытым исходным кодом, созданного Elastic , которое позволяет вам искать, анализировать и визуализировать журналы, созданные из любого источника в любом формате, практика, известная как централизованное ведение журнала

Elastic Stack - состоит из:
Elasticsearch - ядро системы.
Logstash - инструмент сбора, анализа, преобразования и сохранения данных в ES. (elasticsearch)
Kibana - средство визуализации данных (таблицы, графики, панели мониторинга, диаграммы)
Beats - компоненты для сбора и передачи логов и метрик.
X-Pack - позволяет настраивать мониторинг, безопасность, отчеты. 

# Установить Java и другие зависимости
`sudo apt update`
`sudo apt install openjdk-11-jdk wget apt-transport-https curl gnupg2 nginx -y`
Проверим, что установка прошла успешно:
`java -version`
После установки интерпретатора надо провести еще ряд манипуляций, чтобы все работало корректно (почему это не делается
инсталляционным пакетом не представляю). Цель манипуляций - установка в системе переменной среды LS_JAVA_HOME.

А что же в нее писать? Сейчас узнаем с помощью следующей команды:
`sudo update-alternatives --config java`
Нужно выбрать тот, что соответствует 11-й версии и скопировать путь в скобках.

Теперь открывай текстовым редактором файл /etc/environment и давляй туда следующую строку (не забывай про sudo ;) ):
`sudo nano /etc/environment`
`LS_JAVA_HOME="/usr/lib/jvm/java-11-openjdk-amd64"`
`source /etc/environment`
Вот и все. Java установлена и готова к работе. Можно ставить написанные на этом языке приложения.
# Следующий шаг - установка ElasticSearch
ElasticSearch сама по себе заслуживает отдельного урока (а может и не одного) но сегодня мы не будем сильно заострять на ней
внимание. Нам важно знать, что эта БД будет хранить все наши логи и к ней будут обращаться установленные далее программы.
В стандартных репозиториях ElasticSearch нет. Поэтому сначала нужно подключить репозиторий:
<!-- 
curl -fsSL https://artifacts.elastic.co/GPG-KEY-elasticsearch |sudo gpg --dearmor -o /usr/share/keyrings/elastic.gpg
echo "deb [signed-by=/usr/share/keyrings/elastic.gpg] https://artifacts.elastic.co/packages/7.x/apt stable main" | sudo tee -a /etc/apt/sources.list.d/elastic-7.x.list
sudo apt update 
sudo apt install elasticsearch
-->
Настройки хранятся в единственном файле конфигурации: /etc/elasticsearch/elasticsearch.yml. Обрати внимание, что файл в формате
YAML. Он вполне себе текстовый, но оформление специфическое. Постарайся не оставлять лишних отступов и пробелов.
`sudo nano /etc/elasticsearch/elasticsearch.yml`
В блоке Network устанавливаем 
`network.host: localhost`
Мы указали localhost, что Elasticsearch прослушивает все интерфейсы и привязанные IP-адреса. Если вы хотите, чтобы он прослушивал только определенный интерфейс, вы можете указать его IP вместо localhost.
Теперь пропишем сервис в автозагрузку и запустим его:
<!-- 
sudo systemctl daemon-reload
sudo systemctl enable elasticsearch
sudo systemctl start elasticsearch -->
Если видим ошибку, то проверим открыт ли порт 9200 в конфигурации и перезапустим
`sudo systemctl start elasticsearch`
можем поставить утилиту проверки портов и посмотреть все ли работает локально

`sudo apt install net-tools`
`sudo netstat -lpn | grep 9200`
Теперь будем пробовать обратиться на этот порт. 
`curl -X GET "localhost:9200"`
А вот так можно посмотреть состояние сервиса (вид изнутри).
`curl -XGET 'http://localhost:9200/_cluster/health?pretty=true'`

Если ElasticSearch тебе ответил, то установка прошла успешно и БД готова к работе.

Так. БД у нас есть. А кто же будет туда данные складывать? Этим займется LogStash.
# LogStash может фильтровать и форматировать принимаемые логи.
Репозиторий мы в самом начале урока добавили. Все будет ставиться оттуда. Поэтому на этом шаге делай просто:
`sudo apt install logstash`
Конфигурационные файлы лежат в /etc/logstash/conf.d

Для получения дополнительной информации о синтаксисе конфигурации вы можете ознакомиться со справочником по конфигурации , который предоставляет Elastic. 
https://www.elastic.co/guide/en/logstash/current/configuration-file-structure.html
Когда вы настраиваете файл, полезно думать о Logstash как о конвейере, который принимает данные на одном конце, обрабатывает их тем или иным способом и отправляет в пункт назначения (в данном случае пунктом назначения является Elasticsearch). Конвейер Logstash содержит два обязательных элемента input и output. Один необязательный элемент filter. Плагины ввода получают данные из источника, плагины фильтров обрабатывают данные, а плагины вывода записывают данные в место назначения.

Создай файл
`sudo nano /etc/logstash/conf.d/02-beats-input.conf`
и наполни его следующим содержимым:
<!-- 
input {
beats {
port => 5044
}
} -->

Тут мы занимаем порт 5044 по tcp. Это указывает beats вход, который будет прослушивать TCP-порт 5044
# Теперь настроим связь с ElasticSearch.
Вставьте следующую output конфигурацию. По сути, эти выходные данные настраивают Logstash для хранения данных Beats в Elasticsearch, работающем по адресу localhost:9200, в индексе, названном в честь используемого Beat. Бит, используемый в этом уроке, называется Filebeat:
Создавай файл 
`sudo nano /etc/logstash/conf.d/30-elasticsearch-output.conf`
со следующим содержимым:
<!-- 
output {
  if [@metadata][pipeline] {
	elasticsearch {
  	hosts => ["localhost:9200"]
  	manage_template => false
  	index => "%{[@metadata][beat]}-%{[@metadata][version]}-%{+YYYY.MM.dd}"
  	pipeline => "%{[@metadata][pipeline]}"
	}
  } else {
	elasticsearch {
  	hosts => ["localhost:9200"]
  	manage_template => false
  	index => "%{[@metadata][beat]}-%{[@metadata][version]}-%{+YYYY.MM.dd}"
	}
  }
} -->
В конструкции output рекомендую обратить внимание на поле index. Менять его пока не надо. Пусть будет то, что есть.

А вот что оно вообще значит расскажу. В ElasticSearch сущность index по смыслу очень близка к отдельной БД в реляционной СУБД (вроде MySQL или PostgreSQL).

Т.е. получается, что в этом поле пишется шаблон имени, по которому будут создаваться базы данных.

Наверное ты сейчас не очень понял - какие такие базы будут создаваться?

LogStash пишет данные в ElasticSearch. Это ты помнишь? И вот мы задали не конкретную БД, а шаблон, который со временем меняется (и год и месяц и день это переменные).

Если LogStash не нашел созданной БД подходящей под шаблон - он сам ее создаст. Этот принцип полезен тем, что базы данных не разрастаются (ведь каждый день новая) и по каждой в отдельности очень быстро искать.

После того как ты сохранил файлы конфигурации надо проверить, что там нет ошибок.
`sudo -u logstash /usr/share/logstash/bin/logstash --path.settings /etc/logstash -t`
Если выдало что Configuration [OK] то можно запускать LogStash

`sudo systemctl start logstash`
`sudo systemctl enable logstash`
Как результат - ты должен увидеть, что порт 5044 занят.
`sudo netstat -lpn | grep 5044`
Итак. Все. Данные потекли в БД. 

Осталось дело за малым - за визуализацией этих данных.
# За это у нас отвечает Kibana
Установка Kibana будет такой же простой как и у остальных компонентов.

`sudo apt install kibana`
`sudo systemctl start kibana && sudo systemctl enable kibana `
Саму панель через конфиги настраивать не надо. По умолчанию он слушает на интерфейсе локальной петли (127.0.0.1) и не спрашивает пароль на доступ.
Вот казалось бы... жрет как не в себя, но такие детские недоработки =(.
Поэтому регулировать доступ будем с помощью nginx. Ставим если его нет
<!-- 
sudo apt-get install nginx
sudo systemctl enable nginx
sudo systemctl start nginx -->
Теперь создавай файл с паролями и заодно первого пользователя.
`echo "kibanaadmin:`openssl passwd -apr1`" | sudo tee -a /etc/nginx/htpasswd.users`

И завершающим действием будет создание виртуалхоста под кибану - 
`sudo nano /etc/nginx/sites-available/kibana.conf`
<!-- 
server {
listen 80;

server_name 168.119.114.221;

auth_basic "Restricted Access";
auth_basic_user_file /etc/nginx/htpasswd.users;

location / {
proxy_pass http://localhost:5601;
proxy_http_version 1.1;
proxy_set_header Upgrade $http_upgrade;
proxy_set_header Connection 'upgrade';
proxy_set_header Host $host;
proxy_cache_bypass $http_upgrade;
}
} -->
`sudo ln -s /etc/nginx/sites-available/kibana.conf /etc/nginx/sites-enabled/kibana.conf`
И после всех настроек делай 
`sudo nginx -t`
чтобы проверить что нигде не опечатался. И
`sudo systemctl restart nginx`
чтобы применить изменения в настройках.
Итак. С установкой и настройками сервисов закончили. Теперь самое время подключаться к панели и пошуршать уже в ней.
Вводи в адресной строке браузера адрес панели (который задал в nginx.conf).
В моем случае http://168.119.114.221/status
Тебе будет предложено ввести логин и пароль. 

ElasticStack использует несколько облегченных поставщиков данных, называемых Beats, для сбора данных из различных источников и передачи их в Logstash или Elasticsearch. Вот биты, которые в настоящее время доступны в Elastic:
Filebeat : собирает и отправляет лог-файлы.
Metricbeat : собирает метрики из ваших систем и сервисов.
Packetbeat : собирает и анализирует сетевые данные.
Winlogbeat : собирает журналы событий Windows.
Auditbeat : собирает данные фреймворка аудита Linux и отслеживает целостность файлов.
Heartbeat : отслеживает доступность сервисов с помощью активного зондирования.
В этом руководстве мы будем использовать Filebeat для пересылки локальных журналов в наш эластичный стек.
Устанавливаем
`sudo apt install filebeat`
Затем настройте Filebeat для подключения к Logstash. Здесь мы изменим пример файла конфигурации, который поставляется с Filebeat.
Открываем файл конфигурации Filebeat
`sudo nano /etc/filebeat/filebeat.yml`
Для этого найдите output.elasticsearch раздел и закомментируйте следующие строки
<!-- 
Elasticsearch Output
output.elasticsearch:
Array of hosts to connect to
hosts: ["localhost:9200"] -->

Затем раскомментируйте строки output.logstash:и hosts: ["localhost:5044"]
<!-- 
Logstash Output
output.Logstash:
hosts: ["localhost:5044"] -->

Это настроит Filebeat для подключения к Logstash на вашем сервере Elastic Stack через порт 5044, порт, для которого мы ранее указали ввод Logstash
Сохраните и закройте файл
Функциональность Filebeat можно расширить с помощью модулей Filebeat . В этом руководстве мы будем использовать системный модуль, который собирает и анализирует журналы, созданные службой системного ведения журналов распространенных дистрибутивов Linux.
Включим его:
`sudo filebeat modules enable system`
Посмтореть список включенных и отключенных модулей;
`sudo filebeat modules list`
По умолчанию Filebeat настроен на использование путей по умолчанию для системного журнала и журналов авторизации. В случае с этим руководством вам не нужно ничего менять в конфигурации. Посмотреть параметры модуля можно в /etc/filebeat/modules.d/system.yml конфигурационном файле

Теперь нам нужно настроить конвейеры загрузки Filebeat, которые анализируют данные журнала перед их отправкой через logstash в Elasticsearch. Чтобы загрузить конвейер загрузки для системного модуля, введите следующую команду:
`sudo filebeat setup --pipelines --modules system`

Затем загрузите шаблон индекса в Elasticsearch. Индекс Elasticsearch — это набор документов со схожими характеристиками. Индексы идентифицируются по имени, которое используется для ссылки на индекс при выполнении различных операций внутри него. Шаблон индекса будет автоматически применен при создании нового индекса.
Чтобы загрузить шаблон, используйте следующую команду:
`sudo filebeat setup --index-management -E output.logstash.enabled=false -E 'output.elasticsearch.hosts=["localhost:9200"]'`
Filebeat поставляется в комплекте с образцами информационных панелей Kibana, которые позволяют визуализировать данные Filebeat в Kibana. Прежде чем вы сможете использовать информационные панели, вам необходимо создать шаблон индекса и загрузить информационные панели в Kibana.

По мере загрузки информационных панелей Filebeat подключается к Elasticsearch для проверки информации о версии. Чтобы загружать информационные панели, когда Logstash включен, вам необходимо отключить вывод Logstash и включить вывод Elasticsearch:
`sudo filebeat setup -E output.logstash.enabled=false -E output.elasticsearch.hosts=['localhost:9200'] -E setup.kibana.host=localhost:5601`
Через несколько минут вы должны получить примерно такой вывод:
Теперь вы можете запустить и включить Filebeat:
`sudo systemctl start filebeat`
`sudo systemctl enable filebeat`

Если вы правильно настроили свой Elastic Stack, Filebeat начнет отправлять ваш системный журнал и журналы авторизации в Logstash, который затем загрузит эти данные в Elasticsearch.
Чтобы убедиться, что Elasticsearch действительно получает эти данные, запросите индекс Filebeat с помощью этой команды:
`curl -XGET 'http://localhost:9200/filebeat-*/_search?pretty'`

Если ваши выходные данные показывают 0 совпадений, Elasticsearch не загружает никакие журналы в индексе, который вы искали, и вам нужно будет проверить свои настройки на наличие ошибок. Если вы получили ожидаемый результат, перейдите к следующему шагу, на котором мы увидим, как перемещаться по некоторым панелям Kibana.
Допустим готово. 
# Теперь время вернуться к веб-интерфейсу kibana.

В веб-браузере перейдите к полному доменному имени или общедоступному IP-адресу вашего сервера Elastic Stack
Первым делом тебе надо зайти в раздел Discover.
Тут можно увидеть сообщения из базы и делать по ним поиск.
Во время первого запуска Kibana хочет узнать из каких БД - т.е. индексов - ей брать информацию.

Можно задать прямым значением и тогда смотреть будет в одну БД. Можно регулярным выражением и тогда будет охват нескольких БД (возможно даже тех что будут созданы в будущем).

Пока у тебя девственно чистый ElasticSearch можешь вообще задать шаблон идекса - *. Тогда поиск будет по любым созданным индексам.

Под полем для создания шаблона выводятся уже существующие в базе индесы. Они могут подсказать помочь тебе в создании регулярки.
Дальше выбираешь поле по которому будут фильтроваться записи. Это будет как уникальный идентификатор. Можно и без него... но я выбрал . Мне удобно фильтровать сообщения по времени.

Теперь заходи в Discover.

Вот когда ты такое увидел - значит kibana видит данные и можно уже всякие визуализации настраивать.
Для красивого представления данных используется раздел Dashboadrs.

Можно настраивать крутые дашборды.
Состоят все эти дашборды из отдельных кусочков-блоков, которые формируются в других разделах (Discover, Visualize.)

Какие потребности я могу предложить для освоения инструмента:

Диаграмма неудачных заходов по ssh с логом сообщений - т.е. чтобы посмотреть под кем ломились.

На базе этой задачи я покажу тебе как создать простой дашборд.
Тебе нужно сделать несколько неудачных попыток входа по SSH, чтобы эти события попали в логи.
Заходи в Discovery сделай выборку логов по словам ssh AND failure
Убедись что найдено то что надо (иначе скорректируй условия поиска) и жми кнопку Save

Сохранил. Молодец. Теперь иди в раздел Visualize Library. Будем создавать график неудачных авторизаций.

Жми Create visualization, чтобы создать новую визуализацию.

Выбирай Aggregation based

Выбирай тип визуализации Area. Это непрерывный график (в отличие от гистограммы, которая столбиками).

Пока что график состоит только из оси Y. Тебе придется добавить и настроить ось X.

Жми на X Axis
Я показал как заполнить поля. Ты можешь поиграться со значениями и посмотреть как будет изменяться график.

После выставления параметров нужно нажимать кнопку в виде треугольника (как Play на плеере). Ее я тоже отметил на рисунке.

Если выставить параметры как у меня, то увидишь вот такую картинку.
При неудачно выставленном интервале эти пики могут слиться в один, либо может не быть ни одного. Поэтому я выставил интервал оси X в минутах и интервал поиска "Сегодня".
Как только картинка тебя устроит - жми Save

Теперь можно переходить к созданию дашборда. Заходи в раздел Dashboards и жми "создать новый".
Ты увидишь окно конфигуратора. Пока тут ничего нет. Жми Add from library, чтобы добавить элемент.

Как видишь тут можно выбрать из объектов

Нажатие на название объекта добавляет его на панель. Если будешь упорно тыкать и ждать пока это окошко уйдет - натыкаешь кучу одинаковых модулей ;).

Поэтому выбери по одному разу модули и жми на крестик.

Добавленные объекты можно растягивать/сжимать и двигать по рабочему полю.

И вот в результате всех манипуляций у меня получилось вот это:
Вполне симпатично и оба объекта одинаково зависят от выбранного временного диапазона. Как бы ты его ни выставил ты будешь видеть только сообщения, которые прилетели в этот промежуток. И в списке и на графике. Изменяться также будут синхронно.

Если панель нравится, то ее тоже можно сохранить.

И вот урок подошел к концу. Я научил тебя устанавливать и по-минимуму настраивать очень мощную систему работы с логами - ELK или Elastic Stack.

Для полной реализации всех возможностей тебе сначала надо заиметь такие потребности =). А как настраивать я тебе показал. 
